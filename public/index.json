[{"content":"Overview Google Workspace Enterprise plans (successor to G Suite Business plans) include unlimited Google Drive storage for licensed users, but there is a strict 750Gb limit on data a licensed user can upload to their account within 24 hours. This limit is generally quite reasonable and should not pose an issue. The vast majority of people today do not have internet connections sufficient to upload 750Gb of data within 24 hours even if they wanted to. That being said, some people do have sufficient connections, and I\u0026rsquo;m happy to count myself among them (Thanks, altafiber!).\nWith a 250Mb/s upload speed, I have personally run into situations where I happen to need a lot of data, say 800Gb (just over the daily limit), uploaded ASAP. With my connection, I should be able to upload that data in a little more more than 7.5 hours, but instead I\u0026rsquo;m stuck waiting at least 24. Not the end of the world, but frustrating nonetheless. Recently, I used the time I was stuck waiting due to this limit to explore if there were any ways around it. Turns out, there\u0026rsquo;s a couple!\nThe Quick Way The easiest solution is to compress all the data you want to upload to a single file. Zip, Tar, Rar, whatever, just create a compressed archive of your data. There\u0026rsquo;s a million tools out there to make that happen (including those built-in to your OS), but I recommend 7-Zip on Windows, and Keka on macOS. Once you have created your archive, Google Drive will allow you to upload a single file (up to 5Tb in size) without cutting you off after you\u0026rsquo;ve uploaded 750Gb. As soon as that upload completes, assuming 750Gb worth of that file were uploaded within the last 24 hours, you will have triggered your limit and be unable to upload anything else for ~24 hours. Its difficult to tell exactly when the system will unlock and allow uploads again, but hey, at least you got your data uploaded ASAP.\nThe Interesting Way What if, for whatever reason, you don\u0026rsquo;t want to compress your data to an archive? Maybe you don\u0026rsquo;t have enough disk space to store your data and a zip of your data at the same time. There is another way! It involves the scripted use of rclone and Google Workspace service accounts. I do not necessarily recommend this work-around, and highly doubt Google would smile upon it, but it does exist, is technically interesting, and I\u0026rsquo;m hardly the first to write about it\u0026ndash; so lets discuss.\nThe general premise of this work-around is embracing the fact that a single account cannot upload more than 750Gb in a day. No way around that fact. So if a single account can\u0026rsquo;t do it, just use multiple! Simple enough in theory, and not that much more complicated to implement. Also, while this method does theoretically enable abuse of the service, I do not think utilizing it is inherently so. In my opinion, this method can be utilized ethically so long as it is utilized sparingly, and for data which does not exceed 5Tb in size. Google will, after all, accept 5Tb within a day anyway, so long as you compress first. This just saves you a bit of trouble.\n Note I am hardly the first to discover or publicize this method. There are projects floating around online which enable automating this work-around to great effect, allowing uploading of up to 75Tb a day (100x the usual limit). While I find these projects interesting academically, they are more complex to implement than the method I\u0026rsquo;ve detailed below. Furthermore, their entire architecture seems to be built around enabling mass abuse of the Google Workspace Enterprise storage system. Unless you plan to abuse that system en masse (and dare Google to terminate your account while you\u0026rsquo;re at it), I don\u0026rsquo;t think there is much practical need for the additional complexity these projects introduce.\n Implementation Implementing this method for yourself is relatively simple. First, install rclone. It\u0026rsquo;s available for many Operating Systems, including Windows, macOS, and Linux. Once rclone is installed, go ahead and login to your Google Workspace admin panel at admin.google.com.\nFrom the admin panel, navigate to Directory\u0026ndash;\u0026gt;Groups, then click \u0026ldquo;Create Group\u0026rdquo;.\n On the Create Group screen, add a name for the group, an email for the group, and set your account to be the group owner. Lastly, check the box to make it a security group.\n","permalink":"https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/","summary":"Overview Google Workspace Enterprise plans (successor to G Suite Business plans) include unlimited Google Drive storage for licensed users, but there is a strict 750Gb limit on data a licensed user can upload to their account within 24 hours. This limit is generally quite reasonable and should not pose an issue. The vast majority of people today do not have internet connections sufficient to upload 750Gb of data within 24 hours even if they wanted to.","title":"Exploring Google Workspace Upload Limits"},{"content":"Overview It seems appropriate that my first post on this site be an exploration of its own technical underpinnings. That being said, before I get too far into the weeds, a bit of context. When I set out to build my site I had a few goals in mind. Those goals can be reasonably summarized as wanting to build a site from markdown files in Github, and self-host it using docker containers. Simple enough, but lets unpack that a bit:\n Self-Host  Run all website infrastructure in my home, and avoid paying a hosting provider like Squarespace or Wix.   Write all my posts in markdown  Markdown enables easy text-formatting, and allows me to do all my writing in any number of great, markdown-supporting text-editors on basically any computing platform.   Run all infrastructure in containers  Running my web-hosting infrastructure entirely inside docker containers allows me to easily change what computer is running my website in the event that doing so becomes necessary or desirable. Migrating to another computer I own, to a Virtual Private Server (VPS) I rent, or to the Cloud with Azure or AWS container hosting\u0026ndash; it all becomes trivial.   Store the site as a repository in Github  Site files being a Github repo provides me with backups and quick visibility into my site\u0026rsquo;s version history. Additionally, it works alongside the docker containers to keep my site mobile. If I decide to migrate hosts in the future, I won\u0026rsquo;t need to worry about transferring my site files manually. With them in Github, all I would need to do is initiate a git clone of my site\u0026rsquo;s repo on the new host, and the site files are ready to go!    With those goals in mind, I eventually landed on using docker containers of Hugo (to build my site), and NGINX Proxy Manager (to host it). If you would like to do something similar, and build a site like the one you are currently viewing, the below should be helpful! With that out of the way, lets begin.\nRequirements In order to successfully build and host a site using this method, the below are prerequisites:\n Own a domain name. Mine is wallacelabs.tech. If you do not already own one, I recommend purchasing from Hover or Google Domains. As part of owning a domain, you will have control of your domain\u0026rsquo;s DNS records. If you somehow own a domain but do not have the ability to manage its DNS records, you\u0026rsquo;ll have to get that worked out before proceeding. Own an internet-connected computer. This computer will be your web-server. Ideally, that computer will be a server in the sense that it is always on, and dedicated to server functions. While you could host your website on your everyday use computer, I would not recommend it. In terms of actual hardware though? It can be anything from a tiny Raspberry Pi to a massive EPYC Server. The important thing is that it can run docker, is connected to the internet, and is always on. Be able to manage port-forwarding rules on your network\u0026rsquo;s router/gateway. Port-forwarding on your router, along with setting your domain\u0026rsquo;s DNS records, are the two keys required to map traffic from the internet to the web-server hosting your site. Either a Static WAN IP, or a Dynamic DNS configuration. This is required in order for your domain\u0026rsquo;s DNS rules to reliably point traffic to the router on your local network. Most home internet connections do not have static WAN IPs, so you\u0026rsquo;ll likely need to configure a Dynamic DNS (DDNS) service. Stated simply, DDNS is a way of automatically informing your domain\u0026rsquo;s DNS servers of any changes to your home network\u0026rsquo;s Public IP Address. If you use Google Domains as your domain registrar, they have a highly convenient DDNS service built in. If you do not use Google Domains, I would strongly recommend using DuckDNS.   When your website is accessed from the internet, the traffic will follow this general path. Most of the above requirements exist in order to make sure that traffic can reliably traverse this path, allowing your site to be online.\n  If you can check all those boxes, you should be good to go.\nPhase One - Getting Your Site Running Locally Before worrying about domain DNS records, web hosting, and port-forwarding rules, we\u0026rsquo;re going to focus on getting a site running on your local network. First, we\u0026rsquo;ll setup the web-server.\nInstalling Docker In order to setup containers for Hugo and NGINX Proxy Manager, you will need Docker installed on your web-server. Docker runs on Windows, macOS, and Linux, so the Operating System (OS) you use is mostly up to you. It is, however, worth mentioning that less setup is required on Linux and macOS. To run Docker in an ideal manner on Windows, you will need to configure Windows Subsystem for Linux (WSL) and subsequently, a Linux Distribution of your choice to run on WSL. This is not overly complicated, but it is outside the scope of this discussion. A post for another day, perhaps.\n A quick aside: If you plan on using this system as a general purpose home server, in addition to using it as a web-host, it is definitely worth considering the security implications of doing so. By using a computer for web hosting, you are inherently opening up this system to the internet, and there is a lot to be said for the practice of isolating web-hosts on your network through any variety of means. A thorough consideration of these potential risks (and the network hardening measures which might be taken to mitigate them) would be a large digression, and thus is outside the scope of this discussion. Another post for another day, perhaps. For now though, suffice it to say that our risk factor here is not particularly large, due primarily to the fact that we are discussing hosting a static site, not a dynamic one. Had I opted to host a dynamic site using Wordpress, or something of the like, I would be singing a different tune. For additional reading on the security implications of static vs. dynamic sites, see here.\n Begin by installing the Docker Engine using the instructions specific to your OS. Once Docker is installed, you can move on to setting up a Hugo container.\nSetting up a Hugo container To create my site, I utilized a container based on the Hugo Docker Image. Hugo\u0026rsquo;s Docker-Hub image is highly configurable, offering many different tags for specialized integration into custom web-publishing workflows. For my use, all I really wanted was basic container which, when run, provides an interactive shell environment where I can run Hugo commands. The below docker compose file will accomplish this:\n To utilize this compose file to setup your own Hugo container, first, go ahead and download it. Then, open it in your text-editor of choice and update the volume mapping from *PATH TO SITE* in line 6 to wherever you would like your site\u0026rsquo;s git repo to live on your host system. I would recommend creating a folder called site at the root level of your host. If you go that route, just change *PATH TO SITE* to /site and you\u0026rsquo;re good to go. Lastly, open up a Terminal/Powershell session, navigate to whichever folder docker-compose.yml has been downloaded to, and run the following command:\ndocker-compose up You should see the following in your Terminal session:\n Now, open up Docker Desktop and you should see your container running, like this:\n Note that Docker Desktop is only currently available for macOS and Windows, though a Linux version is in Tech Preview, should you wish to try it.\n  With the Hugo container setup and ready to go, you can now use it to create your Hugo site-template.\nCreating your Hugo-Site Now we\u0026rsquo;re in business. Click the \u0026ldquo;CLI\u0026rdquo; button in Docker Desktop to open up a CLI session on your Hugo container. This is how you\u0026rsquo;ll interact with the containerized Hugo program moving forward.\nYour CLI session will have opened up inside the container\u0026rsquo;s /src folder by default. The /src folder is a volume mapped to the host. Whatever data the container puts in this folder, you will be able to access from the host, and vice versa. In docker containers, data inside a volume map like this one is also the only data that will persist after the container is stopped or restarted (i.e. the /src folder is the only thing that does not get deleted when the container stops). The rest of the container is rebuilt from scratch every time the container starts. Given you probably want your Hugo-site to not be deleted after you create it, you will want to create it inside the /src folder. Furthermore, whenever you run Hugo commands, you\u0026rsquo;ll want to run them in this folder. Why? Hugo commands have to be run against a Hugo-site, and this is where your Hugo-site will be located.\nSo, with a CLI session opened at /src, run the below command. When you do, a blank Hugo site template will be initialized as a git repo inside the /src folder. Just be sure to change *YOUR_SITE_NAME* to whatever you would like to call the repo containing your site.\nhugo new site *YOUR_SITE_NAME* The Hugo-site will be generated, and you will see the below message in your CLI session:\n Success!\n  Next up, as indicated in that success message, you\u0026rsquo;ll need to pick a theme and install it. There are tons to choose from! If you are curious, the site you are viewing now is running on PaperMod. Installing your chosen theme is as simple as following the instructions provided by your theme of choice. These instructions usually consist of installing the theme as a git-submodule. This method is convenient as it allows you to easily update your theme by initiating a git pull on that submodule. Put more simply- you\u0026rsquo;ll have a one-click method of updating to a new version of your chosen theme in the future, should you want to do so. As you follow installation instructions, just make sure to run any necessary commands inside the Hugo container\u0026rsquo;s CLI. With a blank Hugo site template created and your theme installed, the foundation of your site is in place.\nCreating your first post With your site created, you can now create a quick test post. Before that though, a brief rabbit-trail about Leaf Bundles.\nTo Leaf-Bundle, or not to Leaf-Bundle  In a moment, you\u0026rsquo;ll run a command that will create the first post on your newly created site. That command is going to create the post as something Hugo calls a Leaf Bundle. I recommend creating all your posts as a leaf bundle because, among other benefits, it allows you to bundle post-images inside the same folder as as the markdown text-file of the post itself. If you do not create your posts as leaf bundles, any images for your posts will be lumped together, completely disorganized, inside a folder named static at the root level of your site. Not ideal. The below diagrams should help visualize this:\n Leaf Bundle Post Structure\n content/ └──posts  └── YOUR_POST_NAME  ├── image1.png  ├── image2.png  └── index.md  Non-Leaf Bundle Post Structure\n content/ ├── posts │ ├── my-post.md │ └── my-other-post.md └── static  ├── my-post_image1.png  ├── my-post_image2.png  ├── my-post_image3.jpg  ├── my-other-post_image1.png  └── my-other-post_image2.jpg  As you accumulate more and more posts, the disorganized pile of images inside /static will continue to get larger and more unwieldy. I highly prefer the structure provided by the leaf bundle method, and I think you will too. Now, back to the business of creating your first post.\nCreating a post (As a Leaf-Bundle!!) Run the below command in the Hugo container CLI to create a test post on your site:\nhugo new content/posts/*YOUR_POST_NAME*/index.md If you wish, feel free to modify index.md to add a quick \u0026ldquo;hello world\u0026rdquo; message, or something of the like, but do not feel obligated. Your first post has been created, whether it has anything written in it or not. With that, time to generate your site!\nGenerating your Site One last command to run now.\nhugo With that, your hugo site has been converted from a pile of markdown documents, images, themes, and the like (that only Hugo can understand) to an actual HTML website that can be displayed by any web browser. You\u0026rsquo;ll find the generated website inside the /public folder created at the root-level of your site\u0026rsquo;s repo.\n This folder is what your web-server will be pushing out to the internet whenever someone accesses your website. Your web-server will only serve the HTML files that are in this folder, so any time you want to update your site, or add a new post, you will need to run the hugo command again to generate your site fresh.\n Hosting your Site! (Locally) Before setting up your newly generated site to be accessed over the internet, we\u0026rsquo;re going to preview it on your local network. Hugo includes a built-in web-host function for this exact purpose. To take advantage of this, run the below command (again, inside the Hugo Container\u0026rsquo;s CLI):\nhugo server With luck, you\u0026rsquo;ll be greeted by the following message:\nOpen http://localhost:1313 in your browser of choice to view your site! As you may have noticed in the above image, the nice thing about previewing your site this way is that Hugo generates the preview in something called \u0026ldquo;Fast Render Mode.\u0026rdquo; Fast Render Mode means you don\u0026rsquo;t have to run the hugo command and regenerate your site every time you want to see a change displayed in your browser. Using the local preview, if you are editing a post, just save any changes you\u0026rsquo;ve made to the index.md file of a given post and you will see them immediately reflected in your browser. Live previewing!\n If you were not so lucky, you may have gotten an error in your CLI session that says something like \u0026ldquo;Check your Hugo installation: you need the extended version to build\u0026hellip;\u0026rdquo;. This is because some themes require an extended version of the Hugo docker image in order to build successfully. Remember earlier, when I said the Hugo image is highly configurable, has many tags, blah blah blah? Here you have a great illustration of that fact. If this happens to you, change line 3 of docker-compose.yml from image: klakegg/hugo:latest to image: klakegg/hugo:ext-alpine. Shut down your container, relaunch it using docker-compose up, and you should be good to go.\n Phase Two - Hosting your Site on the Web! Believe it or not, this should be the easy part. We\u0026rsquo;re going to spin up another container, this time for NGINX Proxy Manager (NPM). NPM (no, not that NPM\u0026hellip; hopefully this is not too confusing) is an awesome web-based GUI built on top of stand-alone NGINX. It is generally used for securely exposing services running on your network to the internet. For example, if you wanted to securely access your Home Assistant Server over the internet, rather than strictly via your home network, or over VPN. In that scenario, you already have a web-server operating a given service or web-app locally, you are just using NPM as a reverse proxy to access that service over the internet. So how can NPM be used to host your site? With a little bit of tricky configuration, NPM can also be used to host static files to the web\u0026ndash; which is exactly what Hugo static sites are!\nBefore setting up NPM, lets quickly configure DNS rules for your domain and add port forwarding rules to your router. Getting this done first prepares the way for traffic to be directed by your domain\u0026rsquo;s nameservers to your web-server running NPM.\nConfiguring your Domain and Router Begin by logging into your domain registrar\u0026rsquo;s website, then pull up the page for managing your domain\u0026rsquo;s DNS records. For me, on Google Domains, it looks like this:\n You will want to create a DNS A record resolving yourDomain.com to your public IP address. Ideally, this address will be static, but most home connections are not. With that in mind, I\u0026rsquo;d recommend configuring Dynamic DNS (DDNS) via Google Domains or Duck DNS, as earlier stated. Without DDNS in place, your site will go down any time the public IP on your home network changes (usually when you reboot your modem). With this DNS record in place, anytime someone accesses yourDomain.com, your domain registrar\u0026rsquo;s nameservers will resolve the request to your home network\u0026rsquo;s router/gateway.\nWith domain DNS rules in place, traffic to your domain will now be pointed to your router. How does your router know what to do with it? Well, you have to tell it what to do. Port-forwarding rules are used to tell your router what traffic to send where. To setup rules telling your router how to handle traffic for your website, you\u0026rsquo;ll begin by logging in to the management interface of your router/gateway. From there, you\u0026rsquo;ll navigate to the Port-Forwarding management page, and add a rule. Unfortunately, I cannot be much more specific than that, as the process will be different on every router. For me though, on a Ubiquiti UniFi based network, it looks like this:\n Make sure to set \u0026lsquo;Forward IP\u0026rsquo; to the IP address of your web-server. Also, double check and make sure your web-server is setup with a static IP address while you\u0026rsquo;re at it. Don\u0026rsquo;t want that changing on you!\n  You\u0026rsquo;re going to need to create two rules here\u0026ndash; one for HTTP traffic coming in over port 80, and another for HTTPS on port 443. You\u0026rsquo;re setting up these rules to point all HTTP and HTTPS traffic coming into your network to your webserver. With those rules in place, you should see something like this:\n You only need to worry about the two rules for HTTP and HTTPS. The other pictured rules are just me censoring my network config.\n  With port forwarding complete, you\u0026rsquo;ve completed the chain such that all traffic going to your domain will reach your web-server, as demonstrated in this image:\n Traffic mapping complete!\n  Setting up an NGINX Proxy Manager container We\u0026rsquo;re nearing the end! Now that\n Your HTML site is sitting in the public folder Your router and domain DNS are configured to point HTTP and HTTPS traffic to your web-server  All thats left is to configure NGINX Proxy Manager to actually serve your website! To do that, use the below docker-compose.yml to create an NPM container on your host. Same drill as before, download the file, and you\u0026rsquo;ll need to make a couple edits before running.\n First, you\u0026rsquo;ll need to chose where on your host system you would like NPM data and LetsEncrypt certificates to live. I recommend creating a folder named container_app_data at the root of your host, with sub-folder NPM. Do that, then just change *PATH* in lines 10 and 11 of docker-compose.yml to /container_app_data/NPM, and docker will automatically create sub-folders for Data and Lets Encrypt at /container_app_data/NPM/data and /container_app_data/NPM/letsencrypt respectively.\nLastly, you\u0026rsquo;ll need to change *PATH TO SITE* in line 12. Set this to be the same as whatever you chose for *PATH TO SITE* when creating the Hugo container. Giving NPM access to *PATH TO SITE*/public will allow it to access your generated site (inside the Hugo container\u0026rsquo;s public folder).\nWith these modifications in place, open a Terminal/Powershell session at the location of docker-compose.yml and run the command:\ndocker-compose up If everything is setup correctly in docker-compose.yml, the container will build and you\u0026rsquo;ll see the following new container in Docker Desktop:\n Two containers now!\n  Configuring NPM for Static-Site Hosting With the NPM container running, open up a browser on your host machine and navigate to http://localhost:81. When you do, you should see the NPM login page:\n To login, use the default username and password:\nEmail: admin@example.com Password: changeme You will then be prompted to setup new login credentials. As with anything, make sure to setup a unique, strong password (I recommend 1Password to help with this). Once you\u0026rsquo;ve setup your new login, click on \u0026ldquo;SSL certificates\u0026rdquo; in the tab bar, then \u0026ldquo;Add SSL Certificate.\u0026rdquo; On this screen, type in your domain name, email and \u0026ldquo;I agree to the Let\u0026rsquo;s Encrypt Terms of Service\u0026rdquo;, like this:\n Before clicking save, make sure to click the \u0026ldquo;Text Server Reachability\u0026rdquo; button. You should see the following message if successful:\n Success here demonstrates traffic from the internet is reaching your web server correctly. Congratulations! You must have setup your domain DNS records and port-forwarding rules successfully. If you don\u0026rsquo;t get a success message here, you might need to go back and double-check those steps. Click the save button, and your SSL certificate will be added:\n With your SSL certificate created, all thats left is to configure a Proxy Host, and your site is live! Click the Hosts tab, then Proxy Hosts. On the Proxy Hosts page, click the Add Proxy Host button. The \u0026ldquo;New Proxy Host\u0026rdquo; screen will pop up. Beginning on the details tab, configure your proxy host like this:\n Obviously be sure to use your actual domain name, not yourDomain.com and www.yourDomain.com\n  Then click on the SSL tab and select the SSL cert you just created, like this:\n Make sure \u0026lsquo;Force SSL\u0026rsquo; and \u0026lsquo;HSTS Enabled\u0026rsquo; are both turned on\n  Lastly, click the Advanced tab, and paste the below as Custom Nginx Configuration.\nlocation / {  root /site/; } like this:\n This is the \u0026rsquo;tricky configuration\u0026rsquo; I mentioned earlier. Thanks to Burke Azbill writing on DimensionQuest.net for figuring this out!\n  This little bit of custom configuration is having NGINX host the static content contained inside the NPM container\u0026rsquo;s /site folder. That folder just so happens to contain your website, as, when you modified the docker-compose.yml for the NPM container, you mapped it to the same location as the public folder your website was generated in. Save this config, and your website should be live! Open up a browser, navigate to your domain name, and there it will be! With your site created, all you have to do now is fill it with content. Congratulations!\nPhase Three - Wrapping Up Lets wrap up by connecting your site up to a Github repo, and discussing some things you can do to enable some general quality-of-life improvements as you manage and continue to develop your site.\nConnecting to GitHub When you first used Hugo to create your site, it initialized your site template inside a git repository. All you need to do now is add this existing repository to GitHub. There are many ways to accomplish this, and this tutorial has gone on long enough, so I won\u0026rsquo;t be verbosely outlining a specific one. In general though, you just need a git client that integrates with Github. Github Desktop works great on Windows and macOS, and there are unofficial forks that run on Linux. If you hate yourself, you can do it exclusively using git in the command-line (I\u0026rsquo;m mostly joking- but if you\u0026rsquo;re working with git exclusively via CLI, you probably don\u0026rsquo;t need to be reading this). You could also do it with tools like Tower, or GitKraken, both premium GUI git clients requiring for-pay licenses.\nPersonally, I enjoy using the source-control integrations built directly into text editors like Atom or Visual Studio Code. With these tools, I can write posts, modify site configuration files, and push up to Github all in one program. Makes it all quite easy.\nUltimately, all you need to do is add your existing local git repo to Github. Pick your favorite way, or try a couple!\nQuality of Life This may sound counterintuitive, but I would recommend setting up an additional development environment on your everyday desktop and/or laptop if you have them. Working directly on the web-server is likely a bit incontinent, if you\u0026rsquo;ve truly set it up to act as a server. Most of the time, my server runs completely headless, with no monitor, keyboard, or mouse attached, but it is running my site\u0026rsquo;s docker containers all the same. Day to day, I do most of my site\u0026rsquo;s development from my laptop. How does that work? This is the benefit of having a site running on docker containers and a Github repository.\nOn my laptop, I\u0026rsquo;ve installed Visual Studio Code, and used it to clone my site\u0026rsquo;s GitHub repo locally. From there, I\u0026rsquo;m able to edit my site as I please. I also have Docker Desktop installed on my laptop, running Hugo inside a container, as we discussed earlier. If I want to preview any changes I\u0026rsquo;ve made, I just start up the Hugo server inside the container, and preview my changes from http://localhost:1313. I usually have the local Hugo server running as I write so that any time I want to check my work, I can quickly save the post I\u0026rsquo;m writing, switch windows, double check how the site will look, and switch back to resume my writing. Whenever I am done with a post and ready to publish, I save my work and run the hugo command inside my local docker container to generate my site fresh inside the public folder. From there, I initiate a git push to sync my changes to GitHub, and remotely initiate a git pull on my web server to sync the changes back down from Github. Boom, changes are live on the web!\nYou can do this on as many computers as you like, enabling truly mobile site development. If you can live without running Hugo locally for previewing, you can even publish to your site from an iPad or smartphone. All you need is a git client. If you want to get really fancy, you can even add another docker container to your web-server called Code-Server. This container enables you to run Visual Studio Code inside a docker container, and interact with it through a web-page. Then you effectively have a full development environment running inside docker containers on your web-server, which can all be remotely accessed over your network.\nLong story short, you have no shortage of options when it comes to convenient ways to manage your site. Figure out which setup is most beneficial to your use-case, and you can make it happen pretty easily.\nWith that, our tale has been told. If you followed along, you should now have a site live on the internet, and many tools at your disposal to manage it. As you begin to create content for your site, you may find it helpful to see additional commands you can run with Hugo, what type of markdown is supported by Hugo as you write posts, and shortcodes Hugo supports for special formatting on top of markdown. Lastly, don\u0026rsquo;t forget to read your theme\u0026rsquo;s documentation for special functionality it may provide to your site (many themes have custom shortcodes for adding additional formatting possibilities to your site, beyond basic markdown and Hugo\u0026rsquo;s built in shortcodes). Thank you for reading, and good luck to you, as the real work has only just begun- time to get writing!\n","permalink":"https://wallacelabs.tech/posts/static-site-hosting-with-docker-hugo-and-nginx-proxy-manger/","summary":"Overview It seems appropriate that my first post on this site be an exploration of its own technical underpinnings. That being said, before I get too far into the weeds, a bit of context. When I set out to build my site I had a few goals in mind. Those goals can be reasonably summarized as wanting to build a site from markdown files in Github, and self-host it using docker containers.","title":"Static Site Hosting for Free with Docker, Hugo, and NGINX Proxy Manger"}]