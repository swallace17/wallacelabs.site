<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Exploring Google Workspace Upload Limits | wallaceLabs</title><meta name=keywords content="unlimited cloud storage,rclone,Google Workspace,bulk upload">
<meta name=description content="Google Workspace Enterprise plans (successor to G Suite Business plans) include unlimited Google Drive storage for licensed users, but there is a strict 750Gb limit on data a licensed user can upload to their account within 24 hours. This limit is generally quite reasonable and should not pose an issue. The vast majority of people today do not have internet connections sufficient to upload 750Gb of data within 24 hours even if they wanted to.">
<meta name=author content="Samuel Wallace">
<link rel=canonical href=https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/>
<meta name=google-site-verification content="XYZabc">
<meta name=yandex-verification content="XYZabc">
<meta name=msvalidate.01 content="XYZabc">
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://wallacelabs.tech/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://wallacelabs.tech/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://wallacelabs.tech/favicon-32x32.png>
<link rel=apple-touch-icon href=https://wallacelabs.tech/apple-touch-icon.png>
<link rel=mask-icon href=https://wallacelabs.tech/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Exploring Google Workspace Upload Limits">
<meta property="og:description" content="Google Workspace Enterprise plans (successor to G Suite Business plans) include unlimited Google Drive storage for licensed users, but there is a strict 750Gb limit on data a licensed user can upload to their account within 24 hours. This limit is generally quite reasonable and should not pose an issue. The vast majority of people today do not have internet connections sufficient to upload 750Gb of data within 24 hours even if they wanted to.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/">
<meta property="og:image" content="https://wallacelabs.tech/cover.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-03-20T15:56:39+00:00">
<meta property="article:modified_time" content="2022-03-20T15:56:39+00:00"><meta property="og:site_name" content="wallaceLabs">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://wallacelabs.tech/cover.png">
<meta name=twitter:title content="Exploring Google Workspace Upload Limits">
<meta name=twitter:description content="Google Workspace Enterprise plans (successor to G Suite Business plans) include unlimited Google Drive storage for licensed users, but there is a strict 750Gb limit on data a licensed user can upload to their account within 24 hours. This limit is generally quite reasonable and should not pose an issue. The vast majority of people today do not have internet connections sufficient to upload 750Gb of data within 24 hours even if they wanted to.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://wallacelabs.tech/posts/"},{"@type":"ListItem","position":3,"name":"Exploring Google Workspace Upload Limits","item":"https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Exploring Google Workspace Upload Limits","name":"Exploring Google Workspace Upload Limits","description":"Google Workspace Enterprise plans (successor to G Suite Business plans) include unlimited Google Drive storage for licensed users, but there is a strict 750Gb limit on data a licensed user can upload to their account within 24 hours. This limit is generally quite reasonable and should not pose an issue. The vast majority of people today do not have internet connections sufficient to upload 750Gb of data within 24 hours even if they wanted to.","keywords":["unlimited cloud storage","rclone","Google Workspace","bulk upload"],"articleBody":"Google Workspace Enterprise plans (successor to G Suite Business plans) include unlimited Google Drive storage for licensed users, but there is a strict 750Gb limit on data a licensed user can upload to their account within 24 hours. This limit is generally quite reasonable and should not pose an issue. The vast majority of people today do not have internet connections sufficient to upload 750Gb of data within 24 hours even if they wanted to. That being said, some people do have sufficient connections, and I’m happy to count myself among them (Thanks, altafiber!).\nWith a 250Mb/s upload speed, I have personally run into situations where I happen to need a lot of data, say 800Gb (just over the daily limit), uploaded ASAP. With my connection, I should be able to upload that data in a little more more than 7.5 hours, but instead I’m stuck waiting at least 24. Not the end of the world, but frustrating nonetheless. Recently, I used the time I was stuck waiting due to this limit to explore if there were any ways around it. Turns out, there’s a couple!\nThe Quick Way The easiest solution is to compress all the data you want to upload to a single file. Zip, Tar, Rar, whatever, just create a compressed archive of your data. There’s a million tools out there to make that happen (including those built-in to your OS), but I recommend 7-Zip on Windows, and Keka on macOS. Once you have created your archive, Google Drive will allow you to upload a single file (up to 5Tb in size) without cutting you off after you’ve uploaded 750Gb. As soon as that upload completes, assuming 750Gb worth of that file were uploaded within the last 24 hours, you will have triggered your limit and be unable to upload anything else for ~24 hours. Its difficult to tell exactly when the system will unlock and allow uploads again, but hey, at least you got your data uploaded ASAP.\nThe Interesting Way What if, for whatever reason, you don’t want to compress your data to an archive? Maybe you don’t have enough disk space to store your data and a zip of your data at the same time. There is another way! It involves the scripted use of rclone and Google Workspace service accounts. I do not necessarily recommend this work-around, and highly doubt Google would smile upon it, but it does exist, is technically interesting, and I’m hardly the first to write about it– so lets discuss.\nThe general premise of this work-around is embracing the fact that a single account cannot upload more than 750Gb in a day. No way around that fact. So if a single account can’t do it, just use multiple! Simple enough in theory, but takes a bit of setup to implement. Also, while this method does theoretically enable abuse of the service, I do not think utilizing it is inherently so. In my opinion, this method can be utilized ethically so long as it is utilized sparingly, and for data which does not exceed 5Tb in size. Google will, after all, accept 5Tb within a day anyway, so long as you compress first. This just saves you a bit of trouble. I personally have all this setup on my linux-based NAS, in the event I ever need to upload more than 750Gb of data on short notice.\n Note I am hardly the first to discover or publicize this method. There are projects floating around online which enable automating this work-around to great effect, allowing uploading of up to 75Tb a day (100x the usual limit). While I find these projects interesting academically, they are more complex to implement than the method I’ve detailed below. Furthermore, their entire architecture seems to be built around enabling mass abuse of the Google Workspace Enterprise storage system. Unless you plan to abuse that system en masse (and dare Google to terminate your account while you’re at it), I don’t think there is much practical need for the additional complexity these projects introduce.\n Implementation Implementing this method for yourself is relatively simple. Quick, high level overview: We’re going to setup some Google Drive service accounts, create a Shared Drive between you and the service accounts, and setup a bash script to automatically utilize and cycle through those service accounts by uploading to Google Drive via rclone. What is rclone? rclone is a great CLI-based tool which enables easily moving data around from one place to another, much like rsync, except it supports cloud services! It’s the only Google drive client I’m aware of that will allow us to programmatically cycle through different accounts as we upload data.\nCreating Service Accounts To make this happen, we’ll begin by creating a couple service accounts. Why service accounts? Service accounts are able to upload 750Gb of data to Google Drive a day, just like a normal account, but they are not a full user account, so you will not be charged licensing fees for them like you would a normal user.\nTo create a service account, go to the Google Developer Console. You must have a project– if you do not already have one, create one. Open your project, click on the hamburger menu in the top left, and navigate to IAM \u0026 Admin-- Service Accounts. Click the Create Service Account button. You will see the below Create Service Account screen, with 3 steps.\n Set a service account name and description. Click Create and Continue. Skip through optional steps 2 and 3.\n  Click the 3-dot actions button on your newly created service account, and navigate to the “Manage Keys” tab. From there, click Add Key--Create New Key--JSON--Create. You’ll be prompted to download the JSON key you just created. Do so, and save it somewhere memorable.\nRepeat these steps to create at least one more service account. In theory, you could create more. Each account can upload 750Gb of data before it hits its limit and we move on to the next one. Personally I setup 4. With my upload speed of 250Mb/s, each account will upload for ~7.5 hours before the 750Gb limit is hit. This allows me to cycle through the 4 accounts over about a 30 hour period before restarting back at beginning and continuing uploading. This worked out great when I needed a little over 3Tb of data uploaded ASAP to share with a co-worker, and zipping the data to an archive was not practical. Do your own math to figure out how many accounts you’ll need to keep your upload live for a full 24-hour period.\n Note: When I earlier mentioned projects floating around on the internet– The process of creating projects, groups, and service accounts is the main thing these tools automate. In my opinion, a responsible use of this workaround will use, at most, a handful of service accounts. These tools will create multiple projects, all with the maximum 100 service accounts, enabling uploading truly absurd amounts of data as fast as one’s upload connection will carry it. A single set of 100 service accounts is “limited” at uploading 75Tb a day! Its because of this that I believe there is no reason to use these tools unless you intend to egregiously abuse the system. I recommend just setting up a handful of service accounts by hand- as I’m outlining here in this post.\n With service accounts created, you should see something like this.\n Adding Service Accounts to a Group Time to move on to creating a group, where each of the service accounts you just created will be a member. This is helpful because when we create a shared drive, you don’t need to add every service account to it individually, you can just add the group and be done. That being said, we are not creating many service accounts, so you could skip this step and just add the service accounts to the shared drive directly, if you want. Might even be faster if you just have 2 accounts.\nBegin by logging into your Google Workspace admin panel at admin.google.com. From the admin panel, navigate to Directory–Groups on the left-hand sidebar, then click “Create Group”.\n On the Create Group screen, add a name for the group, an email for the group, and set your account to be the group owner.\n Click next, and on Group Settings, configure the following:\n Begin by clicking the Restricted preset, then change ‘Who can join the group?’ to Only Invited Users, and finish by changing the ‘Allow members outside your organization’ toggle to ON.\n  With the group created, click the Add members, and type in the email address for each of the service accounts you created earlier. When you’re done, click add to group, and we’re almost done with the Google Workspace side of things. Last up, you need to create a shared drive. This shared drive is where all your service accounts will be uploading data to, shared with your primary account.\nCreating a Shared Drive To create a shared drive, navigate to drive.google.com in your browser. Sign into your account, click Shared Drives in the left-hand navigation bar, and click the New button in the top left. Name your shared drive whatever you like and click create. Your shared drive will be automatically opened, then click the Manage Members button. Now, type in the email you assigned to the group you just created, and grant the group Content Manager permissions. This will allow the service accounts in this group to access the shared drive. Consequently, rclone, running logged into these accounts, will be able to read/write/delete files in this shared drive as necessary.\nInstall rclone and Configure Remotes First, install rclone. It’s available for many Operating Systems, including Windows, macOS, and Linux. Once rclone is installed, open up a Powershell/Terminal session, and type the following command:\nrclone config Follow the prompts to create a new remote. Give it a name and set it to Google Drive using option 16. Now you’ll need to generate an Application Client ID. This ID is what identifies your instance of rclone to the Google Drive API. If you have any trouble following my next few steps, the rclone-provided instructions may prove helpful, but I think you’ll find them quite similar.\nBegin by again logging into the Google Developer Console. Open up the same project you used earlier while creating the service accounts. Using the left-hand navigation bar, navigate to APIs \u0026 Services-- Enabled APIs \u0026 services. Click the + Enabled APIs and Services button at the top. This will open up the API library. Here, we are going to select the Google Drive API and enable it for this project. Search for Google Drive and enable it, like this:\n Now that you’ve enabled the Google Drive API for this project, you can create a credential for rclone to utilize this API by navigating to APIs \u0026 Services-- Credentials. Click + Create Credentials and select the OAuth client ID option. You will see the following:\n Select Desktop App as the application type, and give the OAuth 2.0 client a name\n  Click create and you will be presented with a client ID and a client secret. Be sure to record both, ideally in your password manager (I recommend 1Password).\n Lastly, navigate to APIs \u0026 Services-- OAuth Consent Screen and click the Publish App button to go live with “your app” (rclone). Now, with your Client ID created, return to your Powershell/Terminal Session. Copy the Client ID you recorded a moment ago, and paste it into this CLI session. Next, do the same thing with your Client Secret. Continuing on, select option 1 to allow Full access to all files. You will now be asked to specify a root folder. Leaving this blank will allow rclone to download/upload to any folder in your Google Drive. You can also specify a path to lock rclone’s access to a specific directory (see rclone’s Google Drive documentation for more info).\nNext up, you’ll be asked to specify the path to your Service Account JSON credentials. This is what allows rclone to run logged in as a service account. You downloaded them earlier, while setting up your service accounts. Decide where you’d like them to “live” on your system long term, and copy/paste that path into your CLI session. Continue to follow the prompts until you are asked “Configure this as a Shared Drive (Team Drive)?” Type y, and select the team drive you created earlier. Then wrap up by selecting Yes this is OK and you’re good to go!\nAll that is left now is to repeat this process for each of your service accounts. Don’t worry, you can use the same client-ID and client-secret for all of them, so the remaining rclone remote configuration should go much more quickly. Just be sure that you specify a new Service Account JSON credential for each one!\nWith all your rclone remotes are configured, we’re nearly done. Now you just need to utilize them with a script!\nAuto-Cycle Through Service-Accounts with Scripts! The below bash script will allow you to tie together all the work you’ve done thus far. It will use rclone to begin uploading data to your Shared drive, utilizing a service account until 750Gb has been uploaded, and then switching to the next.\n You will need to substitute in your own path for the data you want to upload. Also, you will need to swap in the names of the rclone remotes you created for each of your service accounts. If you have less than 4 remotes, remove lines as necessary, if you have more, add additional ones in the same format.\nAs I mentioned before, with my internet connection, it takes me ~7.5 hours to upload 750Gb. By the time all 4 of my service accounts have cycled through 750Gb uploaded, I no longer have an upload lock on the first account. With that in mind, If I have more than 3,000Gb to upload, I could simply copy and paste these 4 rclone commands to the end of the script, and it would cycle through every service account twice, uploading nearly 6Tb of data when its all said and done– but then things start to get hairy again, when it comes to abusing the service. Muddy waters, use your best judgment, please don’t abuse the service, you risk your account getting terminated, use at your own risk, don’t give Google reasons to discontinue unlimited cloud storage plans, blah blah blah. I can’t stop you, the information is out there, but its worth bearing in mind nonetheless.\nThis script is provided in bash, for easy use on Linux and macOS systems. You should be able to easily replicate it in Powershell, should you so desire, or just run it via Windows Subsystem for Linux (WSL). In theory, you could even automate the running of this script using cron jobs, or task scheduler on Windows, to regularly upload data without worrying about upload limits slowing you down (again, abuse disclaimer– only so many times I can say this). Lots of options out there.\nI hope you may find this exploration useful in your own bulk-uploading needs but, beyond that, that it might serve as a practical introduction to scripting with rclone. rclone is a great tool to have in your back-pocket, and enables working with all kinds of cloud storage providers (not just Google Drive!) in ways that are difficult or impossible using the first-party clients these services provide. You won’t need to develop a custom solution utilizing a given cloud storage provider’s API– rclone has already done it for you!\n","wordCount":"2608","inLanguage":"en","image":"https://wallacelabs.tech/cover.png","datePublished":"2022-03-20T15:56:39Z","dateModified":"2022-03-20T15:56:39Z","author":{"@type":"Person","name":"Samuel Wallace"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/"},"publisher":{"@type":"Organization","name":"wallaceLabs","logo":{"@type":"ImageObject","url":"https://wallacelabs.tech/favicon.ico"}}}</script>
</head><body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://wallacelabs.tech accesskey=h title="> wallaceLabs (Alt + H)">> wallaceLabs</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div><ul id=menu>
<li>
<a href=https://wallacelabs.tech/archives/ title=archives>
<span>archives</span>
</a>
</li><li>
<a href=https://wallacelabs.tech/categories/ title=categories>
<span>categories</span>
</a>
</li><li>
<a href=https://wallacelabs.tech/search/ title="search (Alt + /)" accesskey=/>
<span>search</span>
</a>
</li><li>
<a href=https://wallacelabs.tech/tags/ title=tags>
<span>tags</span>
</a>
</li></ul></nav></header><main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://wallacelabs.tech>Home</a>&nbsp;»&nbsp;<a href=https://wallacelabs.tech/posts/>Posts</a></div><h1 class=post-title>
Exploring Google Workspace Upload Limits
</h1><div class=post-meta><span title="2022-03-20 15:56:39 +0000 UTC">March 20, 2022</span>&nbsp;·&nbsp;13 min&nbsp;·&nbsp;Samuel Wallace&nbsp;|&nbsp;<a href=https://github.com/swallace17/wallacelabs.site/tree/main/content/posts/Exploring%20Google%20Workspace%20Upload%20Limits/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a>
</div></header><figure class=entry-cover>
<img loading=lazy srcset="https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/cover_hu0a6612ab1c16301476dbbbbe77b2661e_121396_360x0_resize_box_3.png 360w ,https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/cover_hu0a6612ab1c16301476dbbbbe77b2661e_121396_480x0_resize_box_3.png 480w ,https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/cover_hu0a6612ab1c16301476dbbbbe77b2661e_121396_720x0_resize_box_3.png 720w ,https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/cover_hu0a6612ab1c16301476dbbbbe77b2661e_121396_1080x0_resize_box_3.png 1080w ,https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/cover.png 1200w" sizes="(min-width: 768px) 720px, 100vw" src=https://wallacelabs.tech/posts/exploring-google-workspace-upload-limits/cover.png alt width=1200 height=630>
<p>750Gb daily limit?</p></figure><div class=toc>
<details>
<summary accesskey=c title="(Alt + C)">
<span class=details>Table of Contents</span>
</summary>
<div class=inner><ul>
<li>
<a href=#the-quick-way aria-label="The Quick Way">The Quick Way</a></li><li>
<a href=#the-interesting-way aria-label="The Interesting Way">The Interesting Way</a><ul>
<li>
<a href=#note aria-label=Note>Note</a></li><li>
<a href=#implementation aria-label=Implementation>Implementation</a><ul>
<li>
<a href=#creating-service-accounts aria-label="Creating Service Accounts">Creating Service Accounts</a></li><li>
<a href=#adding-service-accounts-to-a-group aria-label="Adding Service Accounts to a Group">Adding Service Accounts to a Group</a></li><li>
<a href=#creating-a-shared-drive aria-label="Creating a Shared Drive">Creating a Shared Drive</a></li><li>
<a href=#install-rclone-and-configure-remotes aria-label="Install rclone and Configure Remotes">Install rclone and Configure Remotes</a></li><li>
<a href=#auto-cycle-through-service-accounts-with-scripts aria-label="Auto-Cycle Through Service-Accounts with Scripts!">Auto-Cycle Through Service-Accounts with Scripts!</a>
</li></ul></li></ul></li></ul></div></details>
</div><div class=post-content><p>Google Workspace Enterprise plans (successor to G Suite Business plans) include unlimited Google Drive storage for licensed users, but <a href="https://apps.google.com/supportwidget/articlehome?hl=en&article_url=https%3A%2F%2Fsupport.google.com%2Fa%2Fanswer%2F172541%3Fhl%3Den&product_context=172541&product_name=UnuFlow&trigger_context=a">there is a strict 750Gb limit</a> on data a licensed user can upload to their account within 24 hours. This limit is generally quite reasonable and should not pose an issue. The vast majority of people today do not have internet connections sufficient to upload 750Gb of data within 24 hours <a href=https://www.speedtest.net/global-index>even if they wanted to</a>. That being said, some people do have sufficient connections, and I&rsquo;m happy to count myself among them (Thanks, <a href=https://www.cincinnatibell.com/>altafiber!</a>).</p><p>With a 250Mb/s upload speed, I have personally run into situations where I happen to need a lot of data, say 800Gb (just over the daily limit), uploaded ASAP. With my connection, I should be able to upload that data in a little more more than 7.5 hours, but instead I&rsquo;m stuck waiting at least 24. Not the end of the world, but frustrating nonetheless. Recently, I used the time I was stuck waiting due to this limit to explore if there were any ways around it. Turns out, there&rsquo;s a couple!</p><h2 id=the-quick-way>The Quick Way<a hidden class=anchor aria-hidden=true href=#the-quick-way>#</a></h2><p>The easiest solution is to compress all the data you want to upload to a single file. Zip, Tar, Rar, whatever, just create a compressed archive of your data. There&rsquo;s a million tools out there to make that happen (including those built-in to your OS), but I recommend <a href=https://www.7-zip.org/>7-Zip</a> on Windows, and <a href=https://www.keka.io/en/>Keka</a> on macOS. Once you have created your archive, Google Drive will allow you to upload a single file (<a href="https://apps.google.com/supportwidget/articlehome?hl=en&article_url=https%3A%2F%2Fsupport.google.com%2Fa%2Fanswer%2F172541%3Fhl%3Den&product_context=172541&product_name=UnuFlow&trigger_context=a">up to 5Tb in size</a>) without cutting you off after you&rsquo;ve uploaded 750Gb. As soon as that upload completes, assuming 750Gb worth of that file were uploaded within the last 24 hours, you will have triggered your limit and be unable to upload anything else for ~24 hours. Its difficult to tell exactly when the system will unlock and allow uploads again, but hey, at least you got your data uploaded ASAP.</p><h2 id=the-interesting-way>The Interesting Way<a hidden class=anchor aria-hidden=true href=#the-interesting-way>#</a></h2><p>What if, for whatever reason, you don&rsquo;t want to compress your data to an archive? Maybe you don&rsquo;t have enough disk space to store your data and a zip of your data at the same time. There is another way! It involves the scripted use of rclone and Google Workspace service accounts. I do not necessarily recommend this work-around, and highly doubt Google would smile upon it, but it does exist, is technically interesting, and I&rsquo;m hardly the first to write about it&ndash; so lets discuss.</p><p>The general premise of this work-around is embracing the fact that a single account cannot upload more than 750Gb in a day. No way around that fact. So if a single account can&rsquo;t do it, just use multiple! Simple enough in theory, but takes a bit of setup to implement. Also, while this method does theoretically enable abuse of the service, I do not think utilizing it is inherently so. In my opinion, this method can be utilized ethically so long as it is utilized sparingly, and for data which does not exceed 5Tb in size. Google will, after all, accept 5Tb within a day anyway, so long as you compress first. This just saves you a bit of trouble. I personally have all this setup on my linux-based NAS, in the event I ever need to upload more than 750Gb of data on short notice.</p><blockquote>
<h3 id=note>Note<a hidden class=anchor aria-hidden=true href=#note>#</a></h3><p>I am hardly the first to discover or publicize this method. There are <a href=https://gist.github.com/korjjs/2c7b256825c5c70fe5b2c33980413d95>projects</a> floating around online which enable automating this work-around to great effect, allowing uploading of up to 75Tb a day (100x the usual limit). While I find these projects interesting academically, they are more complex to implement than the method I&rsquo;ve detailed below. Furthermore, their entire architecture seems to be built around enabling mass abuse of the Google Workspace Enterprise storage system. Unless you plan to abuse that system en masse (and dare Google to terminate your account while you&rsquo;re at it), I don&rsquo;t think there is much practical need for the additional complexity these projects introduce.</p></blockquote><h3 id=implementation>Implementation<a hidden class=anchor aria-hidden=true href=#implementation>#</a></h3><p>Implementing this method for yourself is relatively simple. Quick, high level overview: We&rsquo;re going to setup some Google Drive service accounts, create a Shared Drive between you and the service accounts, and setup a bash script to automatically utilize and cycle through those service accounts by uploading to Google Drive via rclone. What is rclone? rclone is a great CLI-based tool which enables easily moving data around from one place to another, much like <a href=https://www.educba.com/linux-rsync/>rsync</a>, except it supports cloud services! It&rsquo;s the only Google drive client I&rsquo;m aware of that will allow us to programmatically cycle through different accounts as we upload data.</p><h4 id=creating-service-accounts>Creating Service Accounts<a hidden class=anchor aria-hidden=true href=#creating-service-accounts>#</a></h4><p>To make this happen, we&rsquo;ll begin by creating a couple service accounts. Why service accounts? Service accounts are able to upload 750Gb of data to Google Drive a day, just like a normal account, but they are not a full user account, so you will not be charged licensing fees for them like you would a normal user.</p><p>To create a service account, go to the <a href=https://console.cloud.google.com>Google Developer Console</a>. You must have a project&ndash; if you do not already have one, create one. Open your project, click on the hamburger menu in the top left, and navigate to <code>IAM & Admin--> Service Accounts</code>. Click the <code>Create Service Account</code> button. You will see the below <code>Create Service Account</code> screen, with 3 steps.</p><figure class=align-center>
<img loading=lazy src=create-SA.png#center alt="Set a service account name and description. Click Create and Continue. Skip through optional steps 2 and 3."> <figcaption>
<p>Set a service account name and description. Click <code>Create and Continue</code>. Skip through optional steps 2 and 3.</p></figcaption></figure><p>Click the 3-dot actions button on your newly created service account, and navigate to the &ldquo;Manage Keys&rdquo; tab. From there, click <code>Add Key-->Create New Key-->JSON-->Create</code>. You&rsquo;ll be prompted to download the JSON key you just created. Do so, and save it somewhere memorable.</p><p>Repeat these steps to create at least one more service account. In theory, you could create more. Each account can upload 750Gb of data before it hits its limit and we move on to the next one. Personally I setup 4. With my upload speed of 250Mb/s, each account will upload for ~7.5 hours before the 750Gb limit is hit. This allows me to cycle through the 4 accounts over about a 30 hour period before restarting back at beginning and continuing uploading. This worked out great when I needed a little over 3Tb of data uploaded ASAP to share with a co-worker, and zipping the data to an archive was not practical. Do your own math to figure out how many accounts you&rsquo;ll need to keep your upload live for a full 24-hour period.</p><blockquote>
<p><em>Note:</em> When I earlier mentioned <a href=https://gist.github.com/korjjs/2c7b256825c5c70fe5b2c33980413d95>projects floating around on the internet</a>&ndash; The process of creating projects, groups, and service accounts is the main thing these tools automate. In my opinion, a responsible use of this workaround will use, at most, a handful of service accounts. These tools will create multiple projects, all with the maximum 100 service accounts, enabling uploading truly absurd amounts of data as fast as one&rsquo;s upload connection will carry it. A single set of 100 service accounts is &ldquo;limited&rdquo; at uploading 75Tb a day! Its because of this that I believe there is no reason to use these tools unless you intend to egregiously abuse the system. I recommend just setting up a handful of service accounts by hand- as I&rsquo;m outlining here in this post.</p></blockquote><p>With service accounts created, you should see something like this.</p><figure class=align-center>
<img loading=lazy src=service-accounts.png#center>
</figure><h4 id=adding-service-accounts-to-a-group>Adding Service Accounts to a Group<a hidden class=anchor aria-hidden=true href=#adding-service-accounts-to-a-group>#</a></h4><p>Time to move on to creating a group, where each of the service accounts you just created will be a member. This is helpful because when we create a shared drive, you don&rsquo;t need to add every service account to it individually, you can just add the group and be done. That being said, we are not creating many service accounts, so you could skip this step and just add the service accounts to the shared drive directly, if you want. Might even be faster if you just have 2 accounts.</p><p>Begin by logging into your Google Workspace admin panel at <a href=https://admin.google.com/>admin.google.com</a>. From the admin panel, navigate to Directory&ndash;>Groups on the left-hand sidebar, then click &ldquo;Create Group&rdquo;.</p><figure class=align-center>
<img loading=lazy src=groups.png#center>
</figure><p>On the <code>Create Group</code> screen, add a name for the group, an email for the group, and set your account to be the group owner.</p><figure class=align-center>
<img loading=lazy src=create-group.png#center>
</figure><p>Click next, and on <code>Group Settings</code>, configure the following:</p><figure class=align-center>
<img loading=lazy src=group-settings.png#center alt="Begin by clicking the Restricted preset, then change &amp;lsquo;Who can join the group?&amp;rsquo; to Only Invited Users, and finish by changing the &amp;lsquo;Allow members outside your organization&amp;rsquo; toggle to ON."> <figcaption>
<p>Begin by clicking the <code>Restricted</code> preset, then change &lsquo;Who can join the group?&rsquo; to <code>Only Invited Users</code>, and finish by changing the &lsquo;Allow members outside your organization&rsquo; toggle to <code>ON</code>.</p></figcaption></figure><p>With the group created, click the <code>Add members</code>, and type in the email address for each of the service accounts you created earlier. When you&rsquo;re done, click add to group, and we&rsquo;re almost done with the Google Workspace side of things. Last up, you need to create a shared drive. This shared drive is where all your service accounts will be uploading data to, shared with your primary account.</p><h4 id=creating-a-shared-drive>Creating a Shared Drive<a hidden class=anchor aria-hidden=true href=#creating-a-shared-drive>#</a></h4><p>To create a shared drive, navigate to <a href=https://drive.google.com>drive.google.com</a> in your browser. Sign into your account, click <code>Shared Drives</code> in the left-hand navigation bar, and click the <code>New</code> button in the top left. Name your shared drive whatever you like and click <code>create</code>. Your shared drive will be automatically opened, then click the <code>Manage Members</code> button. Now, type in the email you assigned to the group you just created, and grant the group <code>Content Manager</code> permissions. This will allow the service accounts in this group to access the shared drive. Consequently, rclone, running logged into these accounts, will be able to read/write/delete files in this shared drive as necessary.</p><h4 id=install-rclone-and-configure-remotes>Install rclone and Configure Remotes<a hidden class=anchor aria-hidden=true href=#install-rclone-and-configure-remotes>#</a></h4><p>First, <a href=https://rclone.org/downloads/>install rclone</a>. It&rsquo;s available for many Operating Systems, including Windows, macOS, and Linux. Once rclone is installed, open up a Powershell/Terminal session, and type the following command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>rclone config
</span></span></code></pre></div><p>Follow the prompts to create a new remote. Give it a name and set it to <code>Google Drive</code> using option 16. Now you&rsquo;ll need to generate an Application Client ID. This ID is what identifies your instance of rclone to the Google Drive API. If you have any trouble following my next few steps, <a href=https://rclone.org/drive/#making-your-own-client-id>the rclone-provided instructions</a> may prove helpful, but I think you&rsquo;ll find them quite similar.</p><p>Begin by again logging into the <a href=https://console.cloud.google.com>Google Developer Console</a>. Open up the same project you used earlier while creating the service accounts. Using the left-hand navigation bar, navigate to <code>APIs & Services--> Enabled APIs & services</code>. Click the <code>+ Enabled APIs and Services</code> button at the top. This will open up the API library. Here, we are going to select the Google Drive API and enable it for this project. Search for <code>Google Drive</code> and enable it, like this:</p><figure class=align-center>
<img loading=lazy src=drive-API.png#center>
</figure><p>Now that you&rsquo;ve enabled the Google Drive API for this project, you can create a credential for rclone to utilize this API by navigating to <code>APIs & Services--> Credentials</code>. Click <code>+ Create Credentials</code> and select the <code>OAuth client ID</code> option. You will see the following:</p><figure class=align-center>
<img loading=lazy src=o-auth.png#center alt="Select Desktop App as the application type, and give the OAuth 2.0 client a name"> <figcaption>
<p>Select <code>Desktop App</code> as the application type, and give the OAuth 2.0 client a name</p></figcaption></figure><p>Click create and you will be presented with a client ID and a client secret. Be sure to record both, ideally in your password manager (I recommend <a href=https://1password.com/>1Password</a>).</p><figure class=align-center>
<img loading=lazy src=oauth-secret.png#center>
</figure><p>Lastly, navigate to <code>APIs & Services--> OAuth Consent Screen</code> and click the <code>Publish App</code> button to go live with &ldquo;your app&rdquo; (rclone). Now, with your Client ID created, return to your Powershell/Terminal Session. Copy the Client ID you recorded a moment ago, and paste it into this CLI session. Next, do the same thing with your Client Secret. Continuing on, select option 1 to allow <code>Full access to all files.</code> You will now be asked to specify a root folder. Leaving this blank will allow rclone to download/upload to any folder in your Google Drive. You can also specify a path to lock rclone&rsquo;s access to a specific directory (see <a href=https://rclone.org/drive/>rclone&rsquo;s Google Drive documentation</a> for more info).</p><p>Next up, you&rsquo;ll be asked to specify the path to your Service Account JSON credentials. This is what allows rclone to run logged in as a service account. You downloaded them earlier, while setting up your service accounts. Decide where you&rsquo;d like them to &ldquo;live&rdquo; on your system long term, and copy/paste that path into your CLI session. Continue to follow the prompts until you are asked &ldquo;Configure this as a Shared Drive (Team Drive)?&rdquo; Type <code>y</code>, and select the team drive you created earlier. Then wrap up by selecting <code>Yes this is OK</code> and you&rsquo;re good to go!</p><p>All that is left now is to repeat this process for each of your service accounts. Don&rsquo;t worry, you can use the same client-ID and client-secret for all of them, so the remaining rclone remote configuration should go much more quickly. Just be sure that you specify a new Service Account JSON credential for each one!</p><p>With all your rclone remotes are configured, we&rsquo;re nearly done. Now you just need to utilize them with a script!</p><h4 id=auto-cycle-through-service-accounts-with-scripts>Auto-Cycle Through Service-Accounts with Scripts!<a hidden class=anchor aria-hidden=true href=#auto-cycle-through-service-accounts-with-scripts>#</a></h4><p>The below bash script will allow you to tie together all the work you&rsquo;ve done thus far. It will use rclone to begin uploading data to your Shared drive, utilizing a service account until 750Gb has been uploaded, and then switching to the next.</p><script type=application/javascript src=https://gist.github.com/swallace17/6c8e22b1036a82475d0b6be504e5c4c7.js></script>
<p>You will need to substitute in your own path for the data you want to upload. Also, you will need to swap in the names of the rclone remotes you created for each of your service accounts. If you have less than 4 remotes, remove lines as necessary, if you have more, add additional ones in the same format.</p><p>As I mentioned before, with my internet connection, it takes me ~7.5 hours to upload 750Gb. By the time all 4 of my service accounts have cycled through 750Gb uploaded, I no longer have an upload lock on the first account. With that in mind, If I have more than 3,000Gb to upload, I could simply copy and paste these 4 rclone commands to the end of the script, and it would cycle through every service account twice, uploading nearly 6Tb of data when its all said and done&ndash; but then things start to get hairy again, when it comes to abusing the service. Muddy waters, use your best judgment, please don&rsquo;t abuse the service, you risk your account getting terminated, use at your own risk, don&rsquo;t give Google reasons to discontinue unlimited cloud storage plans, blah blah blah. I can&rsquo;t stop you, the information is out there, but its worth bearing in mind nonetheless.</p><p>This script is provided in bash, for easy use on Linux and macOS systems. You should be able to easily replicate it in Powershell, should you so desire, or just run it via Windows Subsystem for Linux (WSL). In theory, you could even automate the running of this script using cron jobs, or task scheduler on Windows, to regularly upload data without worrying about upload limits slowing you down (again, abuse disclaimer&ndash; only so many times I can say this). Lots of options out there.</p><p>I hope you may find this exploration useful in your own bulk-uploading needs but, beyond that, that it might serve as a practical introduction to scripting with rclone. rclone is a great tool to have in your back-pocket, and enables working with all kinds of cloud storage providers (not just Google Drive!) in ways that are difficult or impossible using the first-party clients these services provide. You won&rsquo;t need to develop a custom solution utilizing a given cloud storage provider&rsquo;s API&ndash; rclone has already done it for you!</p></div><footer class=post-footer>
<ul class=post-tags>
<li><a href=https://wallacelabs.tech/tags/unlimited-cloud-storage/>unlimited cloud storage</a></li><li><a href=https://wallacelabs.tech/tags/rclone/>rclone</a></li><li><a href=https://wallacelabs.tech/tags/google-workspace/>Google Workspace</a></li><li><a href=https://wallacelabs.tech/tags/bulk-upload/>bulk upload</a></li></ul><nav class=paginav>
<a class=prev href=https://wallacelabs.tech/posts/operating-an-unraid-hosted-containerized-wireguard-vpn-server-on-a-vlan/>
<span class=title>« Prev Page</span>
<br>
<span>Operating an Unraid-Hosted, Containerized Wireguard VPN Server on a VLAN</span>
</a>
<a class=next href=https://wallacelabs.tech/posts/static-site-hosting-with-docker-hugo-and-nginx-proxy-manger/>
<span class=title>Next Page »</span>
<br>
<span>Static Site Hosting for Free with Docker, Hugo, and NGINX Proxy Manger</span>
</a>
</nav><div class=share-buttons>
<a target=_blank rel="noopener noreferrer" aria-label="share Exploring Google Workspace Upload Limits on twitter" href="https://twitter.com/intent/tweet/?text=Exploring%20Google%20Workspace%20Upload%20Limits&url=https%3a%2f%2fwallacelabs.tech%2fposts%2fexploring-google-workspace-upload-limits%2f&hashtags=unlimitedcloudstorage%2crclone%2cGoogleWorkspace%2cbulkupload"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Exploring Google Workspace Upload Limits on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fwallacelabs.tech%2fposts%2fexploring-google-workspace-upload-limits%2f&title=Exploring%20Google%20Workspace%20Upload%20Limits&summary=Exploring%20Google%20Workspace%20Upload%20Limits&source=https%3a%2f%2fwallacelabs.tech%2fposts%2fexploring-google-workspace-upload-limits%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Exploring Google Workspace Upload Limits on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fwallacelabs.tech%2fposts%2fexploring-google-workspace-upload-limits%2f&title=Exploring%20Google%20Workspace%20Upload%20Limits"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Exploring Google Workspace Upload Limits on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwallacelabs.tech%2fposts%2fexploring-google-workspace-upload-limits%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Exploring Google Workspace Upload Limits on whatsapp" href="https://api.whatsapp.com/send?text=Exploring%20Google%20Workspace%20Upload%20Limits%20-%20https%3a%2f%2fwallacelabs.tech%2fposts%2fexploring-google-workspace-upload-limits%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a>
<a target=_blank rel="noopener noreferrer" aria-label="share Exploring Google Workspace Upload Limits on telegram" href="https://telegram.me/share/url?text=Exploring%20Google%20Workspace%20Upload%20Limits&url=https%3a%2f%2fwallacelabs.tech%2fposts%2fexploring-google-workspace-upload-limits%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg>
</a>
</div></footer></article></main><footer class=footer>
<span>&copy; 2022 <a href=https://wallacelabs.tech>wallaceLabs</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script>
<script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script>
</body></html>